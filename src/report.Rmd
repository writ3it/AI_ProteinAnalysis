---
title: "Basic analysis of ligands"
author: "writ3it"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    highlight: kate
    number_sections: yes
    theme: united
    toc: true
    toc_float: true
params:
  source_url: "https://zenodo.org/record/1040778/files/all_summary.7z"
  zipped: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
working_dir <-getwd()
```

# Summary

to do

# Analysis

## Used R libraries 

- ggplot2 - for visualisations 
- dplyr - for human-friendly data processing 
- DT - for dynamic tables
- archive - for 7z extraction
```{r libs, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
install.packages("psych")

library(psych)

library(ggplot2)
library(dplyr)
library(DT)
devtools::install_github("milesmcbain/friendlyeval")
library(friendlyeval)
# needs libarchive-dev
devtools::install_github("jimhester/archive")
library(archive)
```

## Initialization code
```{r init}
set.seed(23) # for random functions
prettyTable <- function(table_df, round_columns=numeric(), round_digits=2) {
    DT::datatable(table_df, style="bootstrap", filter = "top", rownames = FALSE, extensions = "Buttons", options = list(dom = 'Bfrtip', buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))) %>%
    formatRound(round_columns, round_digits)
} # same look of tables
```

## Data loading

### Downloading dataset
```{r loading}
tempFilePath <- paste(working_dir,"/../data/temp.7z",sep='')
dataFilePath <- paste(working_dir,"/../data/all_summary.csv",sep='')
if (!file.exists(dataFilePath)){
  message("Downloading data from: ",params$source_url);
  download.file(params$source_url,tempFilePath)
  archive_extract(tempFilePath,"./data");
  if (!file.exists(dataFilePath)){
    stop("Data file not found");
  }
} else {
  message("Data was downloaded previously. Be careful!")
}
```



### Reading sample data
```{r sample_data}
sampleRowsNo <- 1000
sample <- read.table(dataFilePath,header = TRUE, nrows = sampleRowsNo, sep = ";");
```
```{r init_data,echo=FALSE}
data <- sample
```

### Dataset attributes lists 

```{r attribs}
#target class for classification
attrib.target_class <- "res_name"
#all attributes
attrib.all <- colnames(data)
#"local" attributes
attrib.local <- attrib.all[ grepl("local_", attrib.all)]
# dict_atom attribs
attrib.dict <- attrib.all[grepl("dict_atom_", attrib.all)]
# parts 
attrib.part <- attrib.all[grepl("part_",attrib.all)]
# skeleton
attrib.skeleton <- attrib.all[grepl("skeleton_",attrib.all)]
# resolution
attrib.res <- "resolution"
# params
attrib.params <- c("fo_col","fc_col","weight_col","grid_space","solvent_radius","solvent_opening_radius")
#uknown columns
attrib.unknown <- c("blob_coverage","blob_volume_coverage_second","resolution_max_limit","FoFc_square_std","res_coverage","res_volume_coverage","FoFc_mean","FoFc_min","blob_volume_coverage","res_volume_coverage_second","FoFc_std","FoFc_max")
# illegal attribs for classifications
attrib.illegal <- c(c(
  "title",
  "pdb_code",
  "res_name",
  "res_id",
  "chain_id",
  "local_",
  "weight_col" #is na!
),
attrib.local, #local are illegal,
attrib.dict, #dicts are illegal,
attrib.unknown,
attrib.params
)

attrib.legal<-setdiff(attrib.all, attrib.illegal)
```
## Data cleansing

### Remove unnecesary ligands (project requirement)
```{r cleansing_1}
excluded_names <- c("UNK", "UNX", "UNL", "DUM", "N", "BLOB", "ALA", "ARG", "ASN", "ASP", "CYS", "GLN", "GLU", "GLY", "HIS", "ILE", "LEU", "LYS", "MET", "MSE", "PHE", "PRO", "SEC", "SER", "THR", "TRP", "TYR", "VAL", "DA", "DG", "DT", "DC", "DU", "A", "G", "T", "C", "U", "HOH", "H20", "WAT");
filtered_data <- data %>%
  filter(!res_name %in% excluded_names) %>%
  filter(!is.na(res_name))
  
```

### Filling data gaps
```{r cleansing_2, message=FALSE}
replacements <<- filtered_data %>% 
  select(c(attrib.legal,attrib.target_class),-c("skeleton_data")) %>% 
  na.omit %>%
  group_by(res_name) %>% 
  summarize_all(funs(mean))

ids <- filtered_data[,attrib.target_class]

#?mutate
for (col in colnames(replacements)){
  column<-filtered_data[,col]
  bad <- is.na(column)
  bad_ids = ids[bad]
  if (sum(bad)==0){
    next
  }
  bad_ids <- data.frame(bad_ids)
  colnames(bad_ids)<-c(attrib.target_class)
  vals <- data.frame(bad_ids) %>% left_join(replacements) %>% select(!!treat_string_as_col(col))
  new_vals <- unlist(vals, use.names = FALSE)
  filtered_data[bad,col] <- new_vals
}

filtered_data <- filtered_data %>% replace(is.na(.),0)
```

## Dataset description
### Simple statistics
```{r desc, show, echo=FALSE}
cat("Number of rows: ",nrow(filtered_data))
cat("Number of attributes: ",ncol(filtered_data))
cat("Number of legal attributes: ",length(attrib.legal))
```
### Attributes
```{r desc_attribs, echo=FALSE}
describe(filtered_data)
```



